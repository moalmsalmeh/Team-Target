{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a833430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ NORMALIZED DATA FOR TARGET VERSION OF PIPELINE\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\brush\\\\Projekt_NLP\\\\normalizedResult.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189c58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE TWO LISTS THAT CONTAIN EACH TEXT OF A TWEET AND ITS TARGET\n",
    "df=df.dropna()\n",
    "target=(df.iloc[0:8132 , 2 ].to_list())\n",
    "text=df.iloc[0:8132, 1 ].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590e677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAME THAT CONTAINS TWEET TEXT AND TARGET\n",
    "df = pd.DataFrame ({'Text': text , 'Target': target })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90096686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  6464\n",
      "Shape of X_test:  1617\n"
     ]
    }
   ],
   "source": [
    "#SPLIT DATA INTO TRAIN AND TEST DATA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text, \n",
    "    target, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022, #-> same order of dataset\n",
    "    stratify=target\n",
    ")\n",
    "print(\"Shape of X_train: \", len(X_train))\n",
    "print(\"Shape of X_test: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c0f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TARGET SPLITTING OF 0.8 DATA###\n",
    "targetPerson=[]\n",
    "targetGroup=[]\n",
    "targetPublic=[]\n",
    "\n",
    "counter=0\n",
    "for t in X_train:\n",
    "    if y_train[counter] == 0:\n",
    "        targetPerson.append(t)\n",
    "    elif y_train[counter] == 1:\n",
    "        targetGroup.append(t)\n",
    "    else:\n",
    "        targetPublic.append(t)\n",
    "    counter+=1\n",
    "###TARGET SPLITTING END###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2724181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UNIQUE WORD SPLITTING OF 0.8 DATA###\n",
    "personWords=[]\n",
    "groupWords=[]\n",
    "publicWords=[]\n",
    "\n",
    "for tweet in targetPerson:\n",
    "    personWords.append(tweet.split())\n",
    "personWords = sum(personWords, [])\n",
    "\n",
    "for tweet in targetGroup:\n",
    "    groupWords.append(tweet.split())\n",
    "groupWords = sum(groupWords, [])\n",
    "\n",
    "for tweet in targetPublic:\n",
    "    publicWords.append(tweet.split())\n",
    "publicWords = sum(publicWords, [])\n",
    "\n",
    "personUnique=[]\n",
    "groupUnique=[]\n",
    "publicUnique=[]\n",
    "\n",
    "for word in personWords:\n",
    "    if word not in personUnique:\n",
    "        personUnique.append(word)\n",
    "        \n",
    "for word in groupWords:\n",
    "    if word not in groupUnique:\n",
    "        groupUnique.append(word)\n",
    "        \n",
    "for word in publicWords:\n",
    "    if word not in publicUnique:\n",
    "        publicUnique.append(word)\n",
    "        \n",
    "onlyPerson=[]\n",
    "\n",
    "for word in personUnique:\n",
    "    if word not in groupUnique:\n",
    "        if word not in publicUnique:\n",
    "            onlyPerson.append(word)\n",
    "            \n",
    "onlyGroup=[]\n",
    "\n",
    "for word in groupUnique:\n",
    "    if word not in personUnique:\n",
    "        if word not in publicUnique:\n",
    "            onlyGroup.append(word)\n",
    "            \n",
    "onlyPublic=[]\n",
    "\n",
    "for word in publicUnique:\n",
    "    if word not in personUnique:\n",
    "        if word not in groupUnique:\n",
    "            onlyPublic.append(word)\n",
    "###UNIQUE WORD SPLITTING END###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c976339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###SKLEARN PIPELINE###\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import xgboost as xgb\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     #('KNN', KNeighborsClassifier())\n",
    "     #('SVM', SVC()),\n",
    "     #('rfc', RandomForestClassifier()) \n",
    "     ('xgb', xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)) \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#4. classfication report BEFORE ANALYZER\n",
    "classificationBefore = classification_report(y_test, y_pred)\n",
    "\n",
    "#5. find accuracy scores\n",
    "accuracyBefore = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#6. count prediction targets\n",
    "personIst=0\n",
    "groupIst=0\n",
    "publicIst=0\n",
    "for p in y_pred:\n",
    "    if p == 0:\n",
    "        personIst+=1\n",
    "    if p == 1:\n",
    "        groupIst+=1\n",
    "    if p == 2:\n",
    "        publicIst+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90c873c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=y_pred\n",
    "countList=[]\n",
    "personCount=0\n",
    "groupCount=0\n",
    "publicCount=0\n",
    "counter=0\n",
    "single_pronouns=[\"du\", \"dich\", \"deinen\"]\n",
    "single_adress=[\"herr\", \"herrn\", \"frau\", \"junge\", \"nazi\"]\n",
    "single_politicians=[\"merkel\", \"söder\", \"spahn\", \"soeder\", \"laschet\", \"baerbock\", \"bundeskanzlerin\", \"bundeskanzler\", \"kanzler\", \"kanzlerin\"]\n",
    "group_pronouns=[\"euch\", \"eure\", \"euer\", \"deren\", \"ihr\"]\n",
    "group_politics=[\"spd\", \"cdu\", \"csu\", \"afd\", \"grünen\", \"grüne\", \"union\", \"linken\", \"nazis\", \"rechten\", \"partei\", \"land\", \"terroristen\", \"demokratie\"]\n",
    "group_countries=[\"deutschland\", \"deutsche\", \"bürger\"]\n",
    "public_pronouns=[\"alle\", \"wir\", \"menschen\", \"volk\", \"bevölkerung\", \"welt\", \"bewohner\"]\n",
    "testList=public_pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69807dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. run analyzer for target correction\n",
    "#7.1 filter out person tweets out of group tweets and correct prediction\n",
    "for s in y_pred2:\n",
    "    if y_pred2[counter] == 1:\n",
    "        doc=X_test[counter].split()\n",
    "        for token in doc:\n",
    "            if token in onlyPerson:\n",
    "                personCount+=1\n",
    "            if token in single_pronouns or token in single_adress or token in single_politicians:\n",
    "                personCount+=1\n",
    "        #7       (0.6239950525664811)\n",
    "        #6       (0.6246134817563389)\n",
    "        #5       (0.6246134817563389) <-- BEST\n",
    "        #4       (0.6246134817563389)\n",
    "        #3       (0.6239950525664811)\n",
    "        if personCount >= 5:\n",
    "            y_pred2[counter]=0\n",
    "        personCount=0\n",
    "    counter+=1\n",
    "counter=0\n",
    "\n",
    "#7.1.1. classfication report AFTER ANALYZER (Step 1/3)\n",
    "classificationAfter = classification_report(y_test, y_pred2)\n",
    "\n",
    "#7.1.2. find accuracy scores\n",
    "accuracyAfter = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "#7.1.3. count prediction targets\n",
    "personIst2=0\n",
    "groupIst2=0\n",
    "publicIst2=0\n",
    "for p in y_pred2:\n",
    "    if p == 0:\n",
    "        personIst2+=1\n",
    "    if p == 1:\n",
    "        groupIst2+=1\n",
    "    if p == 2:\n",
    "        publicIst2+=1\n",
    "\n",
    "#7.2. filter out group tweets out of person tweets and correct prediction\n",
    "for s in y_pred2:\n",
    "    if y_pred2[counter] == 0:\n",
    "        doc=X_test[counter].split()\n",
    "        for token in doc:\n",
    "            if token in onlyGroup:\n",
    "                groupCount+=1\n",
    "            if token in group_pronouns or token in group_politics or token in group_countries:\n",
    "                groupCount+=1\n",
    "        #6       (0.6246134817563389)\n",
    "        #5       (0.6252319109461967) <-- BEST\n",
    "        #4       (0.6252319109461967)\n",
    "        #3       (0.6246134817563389)\n",
    "        #2       (0.6171923314780458)\n",
    "        if groupCount >= 5:\n",
    "            y_pred2[counter]=1\n",
    "        groupCount=0\n",
    "    counter+=1\n",
    "counter=0\n",
    "\n",
    "#7.2.1. classfication report AFTER ANALYZER (Step 2/3)\n",
    "classificationAfter2 = classification_report(y_test, y_pred2)\n",
    "\n",
    "#7.2.2. find accuracy scores\n",
    "accuracyAfter2 = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "#7.2.3. count prediction targets\n",
    "personIst3=0\n",
    "groupIst3=0\n",
    "publicIst3=0\n",
    "for p in y_pred2:\n",
    "    if p == 0:\n",
    "        personIst3+=1\n",
    "    if p == 1:\n",
    "        groupIst3+=1\n",
    "    if p == 2:\n",
    "        publicIst3+=1\n",
    "\n",
    "#7.3. filter out public tweets out of person and group tweets and correct prediction\n",
    "for s in y_pred2:\n",
    "    if y_pred2[counter] == 0 or y_pred2[counter] == 1:\n",
    "        doc=X_test[counter].split()\n",
    "        for token in doc:\n",
    "            if token in onlyPublic:\n",
    "                publicCount+=1\n",
    "            if token in public_pronouns:\n",
    "                publicCount+=1\n",
    "        #6       (0.6252319109461967)\n",
    "        #5       (0.6258503401360545) <-- BEST\n",
    "        #4       (0.6258503401360545)\n",
    "        #3       (0.6190476190476191)\n",
    "        if publicCount >= 5:\n",
    "            y_pred2[counter]=2\n",
    "        publicCount=0\n",
    "    counter+=1\n",
    "counter=0\n",
    "\n",
    "#7.3.1. classfication report AFTER ANALYZER (Step 3/3)\n",
    "classificationAfter3 = classification_report(y_test, y_pred2)\n",
    "\n",
    "#7.3.2. find accuracy scores\n",
    "accuracyAfter3 = accuracy_score(y_test, y_pred2)\n",
    "\n",
    "#7.3.3. count prediction targets\n",
    "personIst4=0\n",
    "groupIst4=0\n",
    "publicIst4=0\n",
    "for p in y_pred2:\n",
    "    if p == 0:\n",
    "        personIst4+=1\n",
    "    if p == 1:\n",
    "        groupIst4+=1\n",
    "    if p == 2:\n",
    "        publicIst4+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665779a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE ANALZYER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67       571\n",
      "           1       0.65      0.68      0.66       642\n",
      "           2       0.51      0.49      0.50       404\n",
      "\n",
      "    accuracy                           0.62      1617\n",
      "   macro avg       0.61      0.61      0.61      1617\n",
      "weighted avg       0.62      0.62      0.62      1617\n",
      "\n",
      "The accuracy of prediction is:  0.6239950525664811\n",
      "IST-WERT BEFORE ANALYZER:\n",
      "Person: 563\n",
      "Group: 670\n",
      "Public: 384\n",
      "###############################################\n",
      "AFTER ANALYZER\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67       571\n",
      "           1       0.65      0.68      0.66       642\n",
      "           2       0.51      0.49      0.50       404\n",
      "\n",
      "    accuracy                           0.63      1617\n",
      "   macro avg       0.61      0.61      0.61      1617\n",
      "weighted avg       0.62      0.63      0.62      1617\n",
      "\n",
      "The accuracy of prediction is:  0.6258503401360545\n",
      "IST-WERT AFTER\n",
      "Person: 559\n",
      "Group: 673\n",
      "Public: 385\n"
     ]
    }
   ],
   "source": [
    "###PRINT ALL CLASSIFICATION REPORTS, ACCURACY SCORES AND TARGET COUNTS###\n",
    "print(\"BEFORE ANALZYER:\")\n",
    "print(classificationBefore)\n",
    "print(\"The accuracy of prediction is: \", accuracyBefore)\n",
    "print(\"IST-WERT BEFORE ANALYZER:\")\n",
    "print(\"Person: \" + str(personIst))\n",
    "print(\"Group: \" + str(groupIst))\n",
    "print(\"Public: \" + str(publicIst))\n",
    "print(\"###############################################\")\n",
    "# print(\"AFTER ANALYZER STEP 1:\")\n",
    "# print(classificationAfter)\n",
    "# print(\"The accuracy of prediction is: \", accuracyAfter)\n",
    "# print(\"IST-WERT AFTER STEP 1:\")\n",
    "# print(\"Person: \" + str(personIst2))\n",
    "# print(\"Group: \" + str(groupIst2))\n",
    "# print(\"Public: \" + str(publicIst2))\n",
    "# print(\"AFTER ANALYZER STEP 2:\")\n",
    "# print(classificationAfter2)\n",
    "# print(\"The accuracy of prediction is: \", accuracyAfter2)\n",
    "# print(\"IST-WERT AFTER STEP 2:\")\n",
    "# print(\"Person: \" + str(personIst3))\n",
    "# print(\"Group: \" + str(groupIst3))\n",
    "# print(\"Public: \" + str(publicIst3))\n",
    "print(\"AFTER ANALYZER\")\n",
    "print(classificationAfter3)\n",
    "print(\"The accuracy of prediction is: \", accuracyAfter3)\n",
    "print(\"IST-WERT AFTER\")\n",
    "print(\"Person: \" + str(personIst4))\n",
    "print(\"Group: \" + str(groupIst4))\n",
    "print(\"Public: \" + str(publicIst4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
