{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce2c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a833430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ NORMALIZED DATA FOR TARGET VERSION OF PIPELINE\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\brush\\\\Projekt_NLP\\\\normalizedResult.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e8d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ DATA THAT CONTAINS UNIQUE WORDS FOR EACH TARGET\n",
    "# onlyPerson=[]\n",
    "# onlyGroup=[]\n",
    "# onlyPublic=[]\n",
    "\n",
    "# personFile = open('onlyPersonWords.txt', 'r', encoding=\"utf-8\")\n",
    "# temp = personFile.readlines()\n",
    "# for line in temp:\n",
    "#     onlyPerson.append(line.replace(\"\\n\", \"\"))\n",
    "    \n",
    "# groupFile = open('onlyGroupWords.txt', 'r', encoding=\"utf-8\")\n",
    "# temp = groupFile.readlines()\n",
    "# for line in temp:\n",
    "#     onlyGroup.append(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "# publicFile = open('onlyPublicWords.txt', 'r', encoding=\"utf-8\")\n",
    "# temp = publicFile.readlines()\n",
    "# for line in temp:\n",
    "#     onlyPublic.append(line.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189c58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8132\n",
      "8132\n"
     ]
    }
   ],
   "source": [
    "#CREATE TWO LISTS THAT CONTAIN EACH TEXT OF A TWEET AND ITS TARGET\n",
    "target = (df.iloc[0:8132 , 2 ].to_list())\n",
    "text= (df.iloc[0:8132, 1 ].to_list())\n",
    "print (len(text))\n",
    "print (len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ad1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDING ADDITIONAL WORDS WITH CORRESPONDING TARGETS\n",
    "# for x in range(0, 2):\n",
    "#     for word in onlyPerson:\n",
    "#         text.append(word)\n",
    "#         target.append(0)\n",
    "#     for word in onlyGroup:\n",
    "#         text.append(word)\n",
    "#         target.append(1)\n",
    "#     for word in onlyPublic:\n",
    "#         text.append(word)\n",
    "#         target.append(2)\n",
    "# print (len(text))\n",
    "# print (len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6dadd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8081\n",
      "8081\n"
     ]
    }
   ],
   "source": [
    "#REMOVAL OF TWEETS WITHOUT ANY CONTENT AND ITS CORRESPONDING ENTRY IN TARGET LIST\n",
    "counter=0\n",
    "for t in text:\n",
    "    if type(t) is float:\n",
    "        text.remove(t)\n",
    "        target.remove(target[counter])\n",
    "    counter+=1\n",
    "\n",
    "print (len(text))\n",
    "print(len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d33eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TOKENISATION OF TWEETS AND LOWERCASING OF WORDS\n",
    "# array=[]\n",
    "\n",
    "# nlp = spacy.load(\"de_core_news_sm\")\n",
    "# for t in text:\n",
    "#     doc = nlp(t)\n",
    "\n",
    "#     temp = [token.lemma_.lower() for token in doc if token.is_alpha \n",
    "# #             and not token.pos_ == 'ADJ' \n",
    "# #             and not token.pos_ == 'CCONJ'\n",
    "# #             and not token.pos_ == 'SCONJ' \n",
    "# #             and not token.pos_ == 'INTJ'\n",
    "# #             and not token.pos_ == 'PREP'\n",
    "# #             and not token.pos_ == 'ADV'\n",
    "# #             and not token.pos_ == 'VERB'\n",
    "# #               and token.pos_ == \"AUX\"\n",
    "# #               or token.pos_ == \"DET\"\n",
    "# #               or token.pos_ == \"NOUN\"\n",
    "# #               or token.pos_ == \"PRON\"\n",
    "# #               or token.pos_ == \"PROPN\"\n",
    "# #               or token.pos_ == \"VERB\"\n",
    "# #               or token.pos_ == \"ADV\"\n",
    "#               ]\n",
    "#     array.append((\" \".join(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48183cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#RANDOMIZER THAT ZIPS TWO CORRESPONDING LISTS TOGETHER AND SHUFFLES BOTH LISTS SYMMETRICALLY\n",
    "# temporary = list(zip(text, target))\n",
    "# random.shuffle(temporary)\n",
    "# text, target = zip(*temporary)\n",
    "# text, target = list(text), list(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590e677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DATAFRAME THAT CONTAINS TWEET TEXT AND TARGET\n",
    "df = pd.DataFrame ({'Text': text , 'Target': target })\n",
    "#print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90096686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  6464\n",
      "Shape of X_test:  1617\n"
     ]
    }
   ],
   "source": [
    "#SPLIT DATA INTO TRAIN AND TEST DATA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text, \n",
    "    target, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022, #-> same order of dataset\n",
    "    stratify=target\n",
    ")\n",
    "print(\"Shape of X_train: \", len(X_train))\n",
    "print(\"Shape of X_test: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c0f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TARGET SPLITTING OF 0.8 DATA###\n",
    "targetPerson=[]\n",
    "targetGroup=[]\n",
    "targetPublic=[]\n",
    "\n",
    "counter=0\n",
    "for t in X_train:\n",
    "    if y_train[counter] == 0:\n",
    "        targetPerson.append(t)\n",
    "    elif y_train[counter] == 1:\n",
    "        targetGroup.append(t)\n",
    "    else:\n",
    "        targetPublic.append(t)\n",
    "    counter+=1\n",
    "###TARGET SPLITTING END###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2724181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UNIQUE WORD SPLITTING OF 0.8 DATA###\n",
    "personWords=[]\n",
    "groupWords=[]\n",
    "publicWords=[]\n",
    "\n",
    "for tweet in targetPerson:\n",
    "    personWords.append(tweet.split())\n",
    "personWords = sum(personWords, [])\n",
    "\n",
    "for tweet in targetGroup:\n",
    "    groupWords.append(tweet.split())\n",
    "groupWords = sum(groupWords, [])\n",
    "\n",
    "for tweet in targetPublic:\n",
    "    publicWords.append(tweet.split())\n",
    "publicWords = sum(publicWords, [])\n",
    "\n",
    "personUnique=[]\n",
    "groupUnique=[]\n",
    "publicUnique=[]\n",
    "\n",
    "for word in personWords:\n",
    "    if word not in personUnique:\n",
    "        personUnique.append(word)\n",
    "        \n",
    "for word in groupWords:\n",
    "    if word not in groupUnique:\n",
    "        groupUnique.append(word)\n",
    "        \n",
    "for word in publicWords:\n",
    "    if word not in publicUnique:\n",
    "        publicUnique.append(word)\n",
    "        \n",
    "onlyPerson=[]\n",
    "\n",
    "for word in personUnique:\n",
    "    if word not in groupUnique:\n",
    "        if word not in publicUnique:\n",
    "            onlyPerson.append(word)\n",
    "            \n",
    "onlyGroup=[]\n",
    "\n",
    "for word in groupUnique:\n",
    "    if word not in personUnique:\n",
    "        if word not in publicUnique:\n",
    "            onlyGroup.append(word)\n",
    "            \n",
    "onlyPublic=[]\n",
    "\n",
    "for word in publicUnique:\n",
    "    if word not in personUnique:\n",
    "        if word not in groupUnique:\n",
    "            onlyPublic.append(word)\n",
    "###WORD SPLITTING END###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc6e294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825a61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c976339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import xgboost as xgb\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     #('KNN', KNeighborsClassifier())\n",
    "     ('SVM', SVC()),\n",
    "     #('rfc', RandomForestClassifier()) \n",
    "     #('xgb', xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)) \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "\n",
    "#print the classfication report BEFORE ANALYZER\n",
    "classificationBefore = classification_report(y_test, y_pred)\n",
    "\n",
    "# find accuracy scores\n",
    "accuracyBefore = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "250ea702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. run analyzer for target correction\n",
    "# bestAcc=0\n",
    "# bestX=0\n",
    "# bestY=0\n",
    "# y_predCopy = y_pred\n",
    "\n",
    "# for x in range(1,10):\n",
    "#     for y in range(1,10):\n",
    "#         personCount = 0\n",
    "#         publicCount = 0\n",
    "#         counter=0\n",
    "#         personVal=False\n",
    "#         publicVal=False\n",
    "\n",
    "#         for p in y_pred:\n",
    "#             if p == 1:\n",
    "#                 doc = X_test[counter].split()\n",
    "#                 for token in doc:\n",
    "#                     if token in onlyPerson:\n",
    "#                         personCount+=1\n",
    "#                     if token in onlyPublic:\n",
    "#                         publicCount+=1\n",
    "\n",
    "#                 if personCount >= x:\n",
    "#                     personVal=True\n",
    "#                 if publicCount >= y:\n",
    "#                     publicVal=True\n",
    "\n",
    "#                 if personVal == True and publicVal == True:\n",
    "#                     y_predCopy[counter] = 2\n",
    "#                 if personVal == True:\n",
    "#                     y_predCopy[counter] = 0\n",
    "#                 else:\n",
    "#                     y_predCopy[counter] = 2\n",
    "\n",
    "#                 personCount = 0\n",
    "#                 publicCount = 0\n",
    "#                 personVal=False\n",
    "#                 publicVal=False\n",
    "#             counter+=1\n",
    "        \n",
    "#         personIst=0\n",
    "#         groupIst=0\n",
    "#         publicIst=0\n",
    "#         for p in y_predCopy:\n",
    "#             if p == 0:\n",
    "#                 personIst+=1\n",
    "#             if p == 1:\n",
    "#                 groupIst+=1\n",
    "#             if p == 2:\n",
    "#                 publicIst+=1\n",
    "        \n",
    "#         if personIst != 0 and groupIst != 0 and publicIst !=0:\n",
    "#             #print the classfication report AFTER ANALYZER\n",
    "#             classificationAfter = classification_report(y_test, y_predCopy)\n",
    "\n",
    "#             # find accuracy scores\n",
    "#             accuracyAfter = accuracy_score(y_test, y_predCopy)\n",
    "#             if accuracyAfter > bestAcc:\n",
    "#                 bestAcc = accuracyAfter\n",
    "#                 bestX = x\n",
    "#                 bestY = y\n",
    "# print(\"Best Acc: \" + str(bestAcc))\n",
    "# print(\"for:\")\n",
    "# print(\"X: \" + str(bestX) + \"     Y: \" + str(bestY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c05480c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: 543\n",
      "Group: 913\n",
      "Public: 161\n"
     ]
    }
   ],
   "source": [
    "personSoll=0\n",
    "groupSoll=0\n",
    "publicSoll=0\n",
    "for p in y_test:\n",
    "    if p == 0:\n",
    "        personSoll+=1\n",
    "    if p == 1:\n",
    "        groupSoll+=1\n",
    "    if p == 2:\n",
    "        publicSoll+=1\n",
    "        \n",
    "personIst=0\n",
    "groupIst=0\n",
    "publicIst=0\n",
    "for p in y_pred:\n",
    "    if p == 0:\n",
    "        personIst+=1\n",
    "    if p == 1:\n",
    "        groupIst+=1\n",
    "    if p == 2:\n",
    "        publicIst+=1\n",
    "print(\"Person: \" + str(personIst))\n",
    "print(\"Group: \" + str(groupIst))\n",
    "print(\"Public: \" + str(publicIst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34655802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the classfication report BEFORE ANALYZER\n",
    "classificationBefore = classification_report(y_test, y_pred)\n",
    "\n",
    "# find accuracy scores\n",
    "accuracyBefore = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69807dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. run analyzer for target correction\n",
    "personCount = 0\n",
    "groupCount = 0\n",
    "publicCount = 0\n",
    "counter=0\n",
    "#best: 3, 3\n",
    "thresholdPerson=1\n",
    "thresholdGroup=1\n",
    "thresholdPublic=1\n",
    "personVal=False\n",
    "groupVal=False\n",
    "publicVal=False\n",
    "single_adress=[\"herr\", \"hr\", \"frau\", \"fr\", \"dame\", \"mr\", \"professor\", \"prof\", \"dr\", \"doktor\", \"doctor\", \"präsident\", \"junge\"]\n",
    "single_politicians=[\"merkel\", \"steinmeier\", \"söder\", \"obama\", \"putin\", \"trump\", \"spahn\"]\n",
    "group_pronouns=[\"euch\", \"eure\", \"euer\", \"euere\", \"deren\"]\n",
    "group_politics=[\"spd\", \"cdu\", \"csu\", \"afd\", \"grünen\", \"grüne\", \"union\", \"linken\", \"nazis\"]\n",
    "public_pronouns=[\"alle\", \"wir\", \"menschen\"]\n",
    "\n",
    "for p in y_pred:\n",
    "    if p == 1:\n",
    "        doc = X_test[counter].split()\n",
    "        for token in doc:\n",
    "            if token in onlyPerson or token in single_adress or token in single_politicians:\n",
    "                personCount+=1\n",
    "            if token in onlyGroup or token in group_pronouns or token in group_politics:\n",
    "                groupCount+=1\n",
    "            if token in onlyPublic or token in public_pronouns:\n",
    "                publicCount+=1\n",
    "                \n",
    "        if personCount >= thresholdPerson:\n",
    "            personVal=True\n",
    "        if groupCount >= thresholdGroup:\n",
    "            groupVal=True\n",
    "        if publicCount >= thresholdPublic:\n",
    "            publicVal=True\n",
    "            \n",
    "        if personVal == True and groupVal == True and publicVal == True:\n",
    "            y_pred[counter] = 2\n",
    "        if personVal == True and groupVal == True:\n",
    "            y_pred[counter] = 1\n",
    "        if personVal == True and publicVal == True:\n",
    "            y_pred[counter] = 0\n",
    "        if groupVal == True and publicVal == True:\n",
    "            y_pred[counter] = 1\n",
    "        if personVal == True:\n",
    "            y_pred[counter] = 0\n",
    "        if groupVal == True:\n",
    "            y_pred[counter] = 1\n",
    "        if publicVal == True:\n",
    "            y_pred[counter] = 2\n",
    "            \n",
    "        personCount = 0\n",
    "        publicCount = 0\n",
    "        personVal=False\n",
    "        publicVal=False\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff96a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person: 543\n",
      "Group: 602\n",
      "Public: 472\n"
     ]
    }
   ],
   "source": [
    "personIst2=0\n",
    "groupIst2=0\n",
    "publicIst2=0\n",
    "for p in y_pred:\n",
    "    if p == 0:\n",
    "        personIst2+=1\n",
    "    if p == 1:\n",
    "        groupIst2+=1\n",
    "    if p == 2:\n",
    "        publicIst2+=1\n",
    "print(\"Person: \" + str(personIst2))\n",
    "print(\"Group: \" + str(groupIst2))\n",
    "print(\"Public: \" + str(publicIst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "873cc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the classfication report AFTER ANALYZER\n",
    "classificationAfter = classification_report(y_test, y_pred)\n",
    "\n",
    "# find accuracy scores\n",
    "accuracyAfter = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665779a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLL-WERT:\n",
      "Person: 571\n",
      "Group: 642\n",
      "Public: 404\n",
      "###############################################\n",
      "BEFORE ANALZYER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.30      0.31       571\n",
      "           1       0.38      0.54      0.45       642\n",
      "           2       0.22      0.09      0.12       404\n",
      "\n",
      "    accuracy                           0.34      1617\n",
      "   macro avg       0.30      0.31      0.29      1617\n",
      "weighted avg       0.32      0.34      0.32      1617\n",
      "\n",
      "The accuracy of prediction is:  0.3432282003710575\n",
      "IST-WERT DAVOR:\n",
      "Person: 543\n",
      "Group: 913\n",
      "Public: 161\n",
      "###############################################\n",
      "AFTER ANALYZER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.30      0.31       571\n",
      "           1       0.40      0.37      0.38       642\n",
      "           2       0.26      0.30      0.28       404\n",
      "\n",
      "    accuracy                           0.33      1617\n",
      "   macro avg       0.32      0.32      0.32      1617\n",
      "weighted avg       0.33      0.33      0.33      1617\n",
      "\n",
      "The accuracy of prediction is:  0.329004329004329\n",
      "IST-WERT DANACH:\n",
      "Person: 543\n",
      "Group: 602\n",
      "Public: 472\n"
     ]
    }
   ],
   "source": [
    "print(\"SOLL-WERT:\")\n",
    "print(\"Person: \" + str(personSoll))\n",
    "print(\"Group: \" + str(groupSoll))\n",
    "print(\"Public: \" + str(publicSoll))\n",
    "print(\"###############################################\")\n",
    "print(\"BEFORE ANALZYER:\")\n",
    "print(classificationBefore)\n",
    "print(\"The accuracy of prediction is: \", accuracyBefore)\n",
    "print(\"IST-WERT DAVOR:\")\n",
    "print(\"Person: \" + str(personIst))\n",
    "print(\"Group: \" + str(groupIst))\n",
    "print(\"Public: \" + str(publicIst))\n",
    "print(\"###############################################\")\n",
    "print(\"AFTER ANALYZER:\")\n",
    "print(classificationAfter)\n",
    "print(\"The accuracy of prediction is: \", accuracyAfter)\n",
    "print(\"IST-WERT DANACH:\")\n",
    "print(\"Person: \" + str(personIst2))\n",
    "print(\"Group: \" + str(groupIst2))\n",
    "print(\"Public: \" + str(publicIst2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
