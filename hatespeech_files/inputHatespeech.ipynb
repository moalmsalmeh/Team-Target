{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\nlp\\\\Entwicklungsdaten.tsv\", sep=\"\\t\")\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\nlp\\\\Trainingsdaten-GermEvalDatei2018.tsv\", sep=\"\\t\", names=[\"c_text\",\"hate\",\"type\",\"score\"])\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\nlp\\\\Trainingsdaten-GermEvalDatei2019.tsv\", sep=\"\\t\", names=[\"c_text\",\"hate\",\"type\",\"score\"])\n",
    "#df3 = pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\nlp\\\\Testdaten.tsv\", sep=\"\\t\")\n",
    "\n",
    "joined_frames = [df, df1, df2]\n",
    "result = pd.concat(joined_frames)\n",
    "text= result.iloc[0:, 1 ]\n",
    "\n",
    "tempArray = []\n",
    "for row in range(len(df1)):\n",
    "    selected_row =df1.iloc[row, 2]\n",
    "    if selected_row == \"INSULT\" or selected_row == \"ABUSE\":\n",
    "        tempArray.append(1)\n",
    "    else:\n",
    "        tempArray.append(0)\n",
    "\n",
    "df1['label'] = pd.Series(tempArray)\n",
    "\n",
    "tempArray = []\n",
    "for row in range(len(df2)):\n",
    "    #print(df1.iloc[row, 2])\n",
    "    selected_row =df2.iloc[row, 2]\n",
    "    if selected_row == \"INSULT\" or selected_row == \"ABUSE\":\n",
    "        tempArray.append(1)\n",
    "    else:\n",
    "        tempArray.append(0)\n",
    "\n",
    "df2['label'] = pd.Series(tempArray)\n",
    "\n",
    "hs = (df.iloc[0: , 8 ].to_list() + df1.iloc[0: , 4].to_list() + df2.iloc[0: , 4].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6690f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "array =[]\n",
    "for t in text[:]:\n",
    "    doc = nlp(t)\n",
    "    #print([token.text for token in doc])\n",
    "    \n",
    "    #normalize dataset\n",
    "    \n",
    "    #with stop words\n",
    "    #temp = [token.lemma_.lower() for token in doc if token.is_alpha] #36\n",
    "    \n",
    "    #without stop words and only alpha\n",
    "    #temp = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    #without stop words and with smileys /no alpha chars\n",
    "    temp = [token.lemma_.lower() for token in doc if not token.is_stop] \n",
    "    \n",
    "    #with smileys and stopwords\n",
    "    #temp = [token.lemma_.lower() for token in doc]\n",
    "    \n",
    "    #print(temp)\n",
    "\n",
    "    array.append((\" \".join(temp)))\n",
    "\n",
    "#print (array)\n",
    "\n",
    "df = pd.DataFrame ({'Text': array , 'Hatespeech': hs })\n",
    "#print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Text, \n",
    "    df.Hatespeech, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2021,#-> same order of dataset random_state=2022, 2021\n",
    "    stratify=df.Hatespeech\n",
    ")\n",
    "\n",
    "#As this dataset is highly imbalance we have to balance this by over sampling\n",
    "\n",
    "trainingdata = {\n",
    "    \"string\": X_train,\n",
    "    \"label\": y_train\n",
    "}\n",
    "newDf = pd.DataFrame(trainingdata)\n",
    "\n",
    "print(newDf)\n",
    "\n",
    "cnt_non_fraud = newDf[newDf['label'] == 0]['string'].count()\n",
    "df_class_fraud = newDf[newDf['label'] == 1]\n",
    "df_class_nonfraud = newDf[newDf['label'] == 0]\n",
    "df_class_fraud_oversample = df_class_fraud.sample(cnt_non_fraud, replace=True)\n",
    "df_oversampled = pd.concat([df_class_nonfraud, df_class_fraud_oversample], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_oversampled['label'].value_counts())\n",
    "print(df_oversampled)\n",
    "\n",
    "X_train = df_oversampled['string']\n",
    "y_train = df_oversampled['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84700e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.datasets import make_classification \n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "#vecktorisieren \n",
    "vectorizer = TfidfVectorizer() \n",
    "Xtrain = vectorizer.fit_transform(X_train) \n",
    "Xtest = vectorizer.transform(X_test) \n",
    "print(Xtrain.shape)\n",
    "\n",
    "#create classifier and train model \n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=2021,# tree_method=\"gpu_hist\", enable_categorical=True,  #booster='gblinear', 2021\n",
    "\n",
    "                        n_estimators = 1000,\n",
    "                        gamma=0.63, #0.61, #2.04\n",
    "                        min_child_weight=0.1,\n",
    "                        reg_alpha=0,\n",
    "                        max_depth=14, #14 27\n",
    "                        colsample_bytree=1, colsample_bylevel=0.5, colsample_bynode=1\n",
    "                         )\n",
    "                        \n",
    "\n",
    "clf.fit(Xtrain, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred \n",
    "y_pred = clf.predict(Xtest)\n",
    "\n",
    "#4. print the classfication report \n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#find accuracy scores\n",
    "accuracy = accuracy_score(y_test, y_pred) \n",
    "print(\"The accuracy of prediction is: \", accuracy)\n",
    "\n",
    "#6. count prediction targets\n",
    "hs=1\n",
    "nhs=0\n",
    "\n",
    "for p in y_pred:\n",
    "    if p == 1:\n",
    "        hs+=1\n",
    "    if p == 0:\n",
    "        nhs+=1\n",
    "print(\"hs: \", hs)\n",
    "print(\"nhs: \", nhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22438a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    choice = input(\"Enter Choice: \")\n",
    "    #print(choice)\n",
    "    \n",
    "    array =[]\n",
    "    doc = nlp(choice)\n",
    "\n",
    "        #without stop words and with smileys /no alpha chars\n",
    "    temp = [token.lemma_.lower() for token in doc if not token.is_stop] # 0.45 f1\n",
    "\n",
    "    array.append((\" \".join(temp)))\n",
    "    \n",
    "    Xtest = vectorizer.transform(array) \n",
    "    y_pred = clf.predict(Xtest)\n",
    "    print(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
